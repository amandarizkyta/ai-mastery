{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"_Fx4stjO4f6O","executionInfo":{"status":"ok","timestamp":1646799237498,"user_tz":-420,"elapsed":14,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}}},"outputs":[],"source":["from math import log"]},{"cell_type":"markdown","metadata":{"id":"SqE8uMBy4f6T"},"source":["## Mean Squared Error"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-XtBajvU4f6W","executionInfo":{"status":"ok","timestamp":1646799237500,"user_tz":-420,"elapsed":12,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}}},"outputs":[],"source":["# calculate mean squared error\n","def mean_squared_error(actual, predicted):\n","    \n","    sum_square_error = 0.0\n","    \n","    for i in range(len(actual)):\n","        sum_square_error += (actual[i] - predicted[i])**2.0\n","    mean_square_error = 1.0 / len(actual) * sum_square_error\n","    return mean_square_error"]},{"cell_type":"markdown","metadata":{"id":"2vH1gY8Y4f6X"},"source":["## Binary Cross Entropy"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"rxfiLtWl4f6Y","executionInfo":{"status":"ok","timestamp":1646799237501,"user_tz":-420,"elapsed":12,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}}},"outputs":[],"source":["# calculate binary cross entropy\n","def binary_cross_entropy(actual, predicted):\n","\n","    sum_score = 0.0\n","    for i in range(len(actual)):\n","        sum_score += actual[i] * log(1e-15 + predicted[i])\n","    mean_sum_score = 1.0 / len(actual) * sum_score\n","    return -mean_sum_score"]},{"cell_type":"markdown","metadata":{"id":"tBXfeetL4f6Z"},"source":["## Categorical Cross Entropy"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"9ETzgOnx4f6a","executionInfo":{"status":"ok","timestamp":1646799237502,"user_tz":-420,"elapsed":11,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}}},"outputs":[],"source":["# calculate categorical cross entropy\n","def categorical_cross_entropy(actual, predicted):\n","    \n","    sum_score = 0.0\n","    for i in range(len(actual)):\n","        for j in range(len(actual[i])):\n","            sum_score += actual[i][j] * log(1e-15 + predicted[i][j])\n","    mean_sum_score = 1.0 / len(actual) * sum_score\n","    return -mean_sum_score"]},{"cell_type":"markdown","metadata":{"id":"eOvexJEY4f6a"},"source":["---"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"03. Deep Learning - Loss Function.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}