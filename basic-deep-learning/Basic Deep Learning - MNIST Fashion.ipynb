{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Basic Deep Learning - MNIST Fashion.ipynb","provenance":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyPsRFQ7YD++hs8AMXS/fTQi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Basic Deep Learning - MNIST Fashion\n","\n","Kita akan melatih jaringan NN untuk mengenali item pakaian dari dataset MNIST Fashion\n","\n","https://github.com/zalandoresearch/fashion-mnist\n","\n","Training set of 60,000 examples and a test set of 10,000 examples. Setiap item adalah gambar grayscale 28*28 pixel.\n","\n","![alt text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"],"metadata":{"id":"aAB9s-L-ktIb"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LoBO7dzukocN","executionInfo":{"status":"ok","timestamp":1646962251740,"user_tz":-420,"elapsed":2925,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"0e44eeb8-7777-4c8d-edd8-babfeed75601"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}],"source":["import tensorflow as tf\n","\n","print(tf.__version__)"]},{"cell_type":"markdown","source":["# A. Load Data\n","\n","Data sudah tersedia di `tf.keras.datasets` API."],"metadata":{"id":"8A97SSLlmGn9"}},{"cell_type":"code","source":["mnist = tf.keras.datasets.fashion_mnist"],"metadata":{"id":"e5nxGiCal81e","executionInfo":{"status":"ok","timestamp":1646962329857,"user_tz":-420,"elapsed":6,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Memanggil `load_data`. Objek ini akan memberikan dua set data. Tapi perlu didefinisikan mana yang gambar latih & label gambar latih."],"metadata":{"id":"_gNgLQN6mwhe"}},{"cell_type":"code","source":["# https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data\n","\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e3txZH0ZmsQK","executionInfo":{"status":"ok","timestamp":1646962444069,"user_tz":-420,"elapsed":935,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"91473c77-95c9-4056-8f19-295be4fc4e2d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["## Check Sample Data\n","\n","Kita akan cek seperti data yang telah kita miliki"],"metadata":{"id":"-B2TjnxYnp33"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# cek sample data dengan index tertentu\n","# [0] merupakan index pada data, anda bisa ganti index ini\n","\n","\n","plt.imshow(training_images[8])\n","\n","print('Label', training_labels[8])\n","print('Data Image', training_images[8])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-sHHr0wDnxRL","executionInfo":{"status":"ok","timestamp":1646963198975,"user_tz":-420,"elapsed":9,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"d8d823d3-f07f-4c90-de9e-f4f0c965c4cc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Label 5\n","Data Image [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   1   3   1   0   0   1\n","    1   0   0   0   0  58   0  39   1   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   1   3   0   0   0   0\n","    0   0   0  64 109 146 192 193   7   0]\n"," [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0  94  38\n","   99 209 183 229 192 142  48   0   0   0]\n"," [  0   0   0   0   0   0   0   0   0   1   0   0   0   0  41  45 158 146\n","  164 114  51   1  53 105  42  36   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0  10  68  44  30  59 172\n","  146   0  22   0  13 103 111 103   0   0]\n"," [  0   0   0   0   0   0   0   0   0   3   1   0  22  61  88 152 255  71\n","    0   0   0   0  35  85 112 201  44   0]\n"," [  0   0   0   0   0   0   0   0   0   1   0   0  13  62 154  62   0   0\n","    0   0   0   0  54  99  61 106  51  19]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9   1\n","    0   0   1   0  79  82  47  33  58  50]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   3   1   3   9   3\n","    0   0   1   0 100  88  48  35  70  54]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3\n","    0   1   0   0 111 195 119  29  58  45]\n"," [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n","    3   3   0   0  91 146 171  16  93  35]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0  48  45   3  79  87  99   6]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3\n","    0   0 119 137  33  96  77  13  45   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   32 160 164 142 116  79  82  39  39   0]\n"," [  0   0   0   0   3   0   0   0   0   0   0   0   0   3   4  10   0  41\n","  180 142 171   1   0   0  48  73  16   0]\n"," [  0   0   0   0   0   0   1   1   0   0   0   0   0   0   3   0  27 155\n","  114 169   0   0   0   0  47  76   6   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0 155 129\n","  160   0   0   0   0   0  45  96   0   0]\n"," [  0   0   0   0   1   0  16  39  64   0   0   0   0   0   0 129 151 175\n","    0   0   0   4   4   0  48 116   0   0]\n"," [  0   0   0   0   0   0  58  87  73  10   0   0   0   0  27 187 195   0\n","    0   0   0   3   1   0  47 146   0   0]\n"," [  1   0   0   0   1   0   0   0   0   0   0   0   0   0 181 225  45   0\n","    0   0   0   0   1   0  45 186   0   0]\n"," [  0   0   0   0   0   0   1 183 210  90   0   0   0 126 253 142   0   0\n","    0   0   0   0   1   0  48 203   0   0]\n"," [ 64  58  45  27  16   9   1 175 245 204  22   0  70 236 190   6   0   0\n","    0   0   0   0   0   0  50 196   0   0]\n"," [ 96 128 149 163 158 140 138 146 154 108  90 148 193 177  36   0   7   0\n","    0   0   0   0   0   0  41 125   0   0]\n"," [  0   0   0   0  19  47  65  93  94 125 166 180 119  29   0   0   0   0\n","    0   0   0   0   0   0  32 238   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0 131   0   0]\n"," [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0]]\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Data asli terdiri antara angka 0 dan 255. Jika kita latih dengan jaringan NN, itu akan lebih mudah jika kita buat semua nilainya diantara 0 dan 1. \n","\n","Proses ini yang disebut sebagai 'normalisasi'."],"metadata":{"id":"toDxfrQUpiS3"}},{"cell_type":"code","source":["training_images = training_images / 255.0\n","test_images = test_images / 255.0"],"metadata":{"id":"FYkpcX25qYve","executionInfo":{"status":"ok","timestamp":1646963386154,"user_tz":-420,"elapsed":578,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["print('Data Image', training_images[8])\n","plt.imshow(training_images[8])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"XrteJjEAquCG","executionInfo":{"status":"ok","timestamp":1646963459982,"user_tz":-420,"elapsed":419,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"9e325e6a-d76c-4c02-8062-f028fd199807"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Data Image [[0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.00392157 0.01176471 0.00392157 0.         0.         0.00392157\n","  0.00392157 0.         0.         0.         0.         0.22745098\n","  0.         0.15294118 0.00392157 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.00392157 0.01176471 0.         0.         0.         0.\n","  0.         0.         0.         0.25098039 0.42745098 0.57254902\n","  0.75294118 0.75686275 0.02745098 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.00392157 0.         0.\n","  0.         0.         0.         0.         0.36862745 0.14901961\n","  0.38823529 0.81960784 0.71764706 0.89803922 0.75294118 0.55686275\n","  0.18823529 0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.00392157 0.         0.\n","  0.         0.         0.16078431 0.17647059 0.61960784 0.57254902\n","  0.64313725 0.44705882 0.2        0.00392157 0.20784314 0.41176471\n","  0.16470588 0.14117647 0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.03921569 0.26666667 0.17254902 0.11764706 0.23137255 0.6745098\n","  0.57254902 0.         0.08627451 0.         0.05098039 0.40392157\n","  0.43529412 0.40392157 0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.01176471 0.00392157 0.\n","  0.08627451 0.23921569 0.34509804 0.59607843 1.         0.27843137\n","  0.         0.         0.         0.         0.1372549  0.33333333\n","  0.43921569 0.78823529 0.17254902 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.00392157 0.         0.\n","  0.05098039 0.24313725 0.60392157 0.24313725 0.         0.\n","  0.         0.         0.         0.         0.21176471 0.38823529\n","  0.23921569 0.41568627 0.2        0.0745098 ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.03529412 0.00392157\n","  0.         0.         0.00392157 0.         0.30980392 0.32156863\n","  0.18431373 0.12941176 0.22745098 0.19607843]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.01176471 0.00392157 0.01176471 0.03529412 0.01176471\n","  0.         0.         0.00392157 0.         0.39215686 0.34509804\n","  0.18823529 0.1372549  0.2745098  0.21176471]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.01176471\n","  0.         0.00392157 0.         0.         0.43529412 0.76470588\n","  0.46666667 0.11372549 0.22745098 0.17647059]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.00392157 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.01176471 0.01176471 0.         0.         0.35686275 0.57254902\n","  0.67058824 0.0627451  0.36470588 0.1372549 ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.18823529 0.17647059 0.01176471\n","  0.30980392 0.34117647 0.38823529 0.02352941]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.01176471\n","  0.         0.         0.46666667 0.5372549  0.12941176 0.37647059\n","  0.30196078 0.05098039 0.17647059 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.1254902  0.62745098 0.64313725 0.55686275 0.45490196 0.30980392\n","  0.32156863 0.15294118 0.15294118 0.        ]\n"," [0.         0.         0.         0.         0.01176471 0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.01176471 0.01568627 0.03921569 0.         0.16078431\n","  0.70588235 0.55686275 0.67058824 0.00392157 0.         0.\n","  0.18823529 0.28627451 0.0627451  0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.00392157 0.00392157 0.         0.         0.         0.\n","  0.         0.         0.01176471 0.         0.10588235 0.60784314\n","  0.44705882 0.6627451  0.         0.         0.         0.\n","  0.18431373 0.29803922 0.02352941 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.00392157 0.         0.         0.         0.60784314 0.50588235\n","  0.62745098 0.         0.         0.         0.         0.\n","  0.17647059 0.37647059 0.         0.        ]\n"," [0.         0.         0.         0.         0.00392157 0.\n","  0.0627451  0.15294118 0.25098039 0.         0.         0.\n","  0.         0.         0.         0.50588235 0.59215686 0.68627451\n","  0.         0.         0.         0.01568627 0.01568627 0.\n","  0.18823529 0.45490196 0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.22745098 0.34117647 0.28627451 0.03921569 0.         0.\n","  0.         0.         0.10588235 0.73333333 0.76470588 0.\n","  0.         0.         0.         0.01176471 0.00392157 0.\n","  0.18431373 0.57254902 0.         0.        ]\n"," [0.00392157 0.         0.         0.         0.00392157 0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.70980392 0.88235294 0.17647059 0.\n","  0.         0.         0.         0.         0.00392157 0.\n","  0.17647059 0.72941176 0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.00392157 0.71764706 0.82352941 0.35294118 0.         0.\n","  0.         0.49411765 0.99215686 0.55686275 0.         0.\n","  0.         0.         0.         0.         0.00392157 0.\n","  0.18823529 0.79607843 0.         0.        ]\n"," [0.25098039 0.22745098 0.17647059 0.10588235 0.0627451  0.03529412\n","  0.00392157 0.68627451 0.96078431 0.8        0.08627451 0.\n","  0.2745098  0.9254902  0.74509804 0.02352941 0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.19607843 0.76862745 0.         0.        ]\n"," [0.37647059 0.50196078 0.58431373 0.63921569 0.61960784 0.54901961\n","  0.54117647 0.57254902 0.60392157 0.42352941 0.35294118 0.58039216\n","  0.75686275 0.69411765 0.14117647 0.         0.02745098 0.\n","  0.         0.         0.         0.         0.         0.\n","  0.16078431 0.49019608 0.         0.        ]\n"," [0.         0.         0.         0.         0.0745098  0.18431373\n","  0.25490196 0.36470588 0.36862745 0.49019608 0.65098039 0.70588235\n","  0.46666667 0.11372549 0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.1254902  0.93333333 0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.51372549 0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]]\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fee17b38210>"]},"metadata":{},"execution_count":9},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARc0lEQVR4nO3de4wd5XkG8OfZ9V7Al2ADXnzlYmyoIY0JiwmEBAgtt7YCKoVCReRUCKcSpCCoGkSlBLV/FKUlKVIQlQnUTpuA0iYIq3VbXIuLyMVlDQZsE4IxdvHiC9jg9XrZ9V7e/rEDXWC/d5Yz55w54X1+0mrPznvmzOfZfTznzDfzfTQziMgnX1PZDRCR+lDYRYJQ2EWCUNhFglDYRYKYVM+NtbLN2jG5npsUCaUfh3DYBjherVDYSV4K4B4AzQC+b2Z3ec9vx2SczYuKbFJEHOttXbJW8dt4ks0A7gVwGYDFAK4lubjS1xOR2irymX0pgK1mts3MDgN4GMAV1WmWiFRbkbDPAfD6mJ93Zss+gORykl0kuwYxUGBzIlJEzc/Gm9kKM+s0s84WtNV6cyKSUCTs3QDmjfl5brZMRBpQkbA/A2AhyRNJtgK4BsDq6jRLRKqt4q43MxsieROA/8Jo19uDZra5ai0Tkaoq1M9uZmsArKlSW0SkhnS5rEgQCrtIEAq7SBAKu0gQCrtIEAq7SBB1vZ9dSsBxb23+/3Jzs1u34WH/9YuMTpzTtlwljow8cPlZbr1tzTNunZ2nJ2u2IedylQr/3TqyiwShsIsEobCLBKGwiwShsIsEobCLBKGuN/HVsnurxK6zvqvOduv7Tve7JPsX+EOsnf/NqW69CduTtTe+dIS77khfn1tPb1NEQlDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglA/eyPIu9WzSH90zro2NFT5a0/A7pvPTdZmPX3AXbf7wk+59euWrXXrP9u/IFn7i7nfd9f95zfT7QaAJzad4tZ3fuNkt9705HNuvRZ0ZBcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQv3s4lv6abdsLf5934fPO5is/fqMdnfdqUe97db/8ZHfcetznjicrH378d921x28aJFbP/KsVrfeNNDr15csTtZGNm5x161UobCT3A7gIIBhAENm1lmNRolI9VXjyH6hmb1VhdcRkRrSZ3aRIIqG3QA8RnIDyeXjPYHkcpJdJLsG4Y/bJSK1U/Rt/Hlm1k1yJoC1JH9lZk+NfYKZrQCwAgCmcUZ5IwyKBFfoyG5m3dn3vQAeAbC0Go0SkeqrOOwkJ5Oc+t5jABcD2FStholIdRV5G98B4BGO3os9CcCPzOw/q9KqaGo4fnrztGlu/cAlv+XWJ3f3u/VJ+w+59Y6VRyVrg1/f5667a/d0t77wm79w65OOn5esDeXs8/bnXnPr7DzVrf/vJVPcerNz+mrORnfVilUcdjPbBuAzVWyLiNSQut5EglDYRYJQ2EWCUNhFglDYRYLQLa4NgJP8X4MND/sv4HQjcbo/HPOkfr8L6q3PHOnWe77gD4O99YL7k7Vzb/1Td92FD//SrecZ2vF6xeva3A633rbf3299s/39ctnV6W7D55/yO7n48+fdeoqO7CJBKOwiQSjsIkEo7CJBKOwiQSjsIkEo7CJBqJ+9ARTpR8997V7/FlTL+e++94t9bn32w21u/ZI/XpKsTUWxfvRaGuiY7NYPT/P70Wdu8KfCXnP4nGTtuHZ/+Lb2ObOTNe5pSdZ0ZBcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQv3sjaCGQ0kP79vv1o949H/c+omPFtt+09SpydpIrz+tceH9QqcvPOe1e2en+6sBoO1tf/3Wdwbd+vzVPcnau/PT+wwABhYdl6zZAfWzi4SnsIsEobCLBKGwiwShsIsEobCLBKGwiwShfvbgio5Zz+bmyreds64N+feE19K7x/r3q7f05lwDkHcYbU6//uGp/n5pGkpv25xm5x7ZST5Ici/JTWOWzSC5luQr2Xd/Im0RKd1E3savBHDph5bdDmCdmS0EsC77WUQaWG7YzewpAB++5vIKAKuyx6sAXFnldolIlVX6mb3DzHZlj3cDSE6MRXI5gOUA0A5/3jARqZ3CZ+PNzAAkzxiY2Qoz6zSzzhb4gxOKSO1UGvY9JGcBQPZ9b/WaJCK1UGnYVwNYlj1eBqDgjZAiUmu5n9lJPgTgAgDHkNwJ4FsA7gLwY5LXA9gB4OpaNlJqp2hfdt76dvBgspbXx5/Lu18dKHQ//FDO6aVzv7zRrT++Lj1ePgCcvDK9X1oP+tc2TDqU3uccSf+bc/e2mV2bKF2Ut66INA5dLisShMIuEoTCLhKEwi4ShMIuEoRuca2GGnYBfZLlddsV7Zor0q3Yvs+vr92y2K13LMm5zuyddNfbOyfPdFed9WR6CG4Op//WdGQXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQmEXCUL97NWgfvSaqOVQ0iPnn+HWj32uz613/MMmt77/urPc+u6r0n3pw63uqsDLr6Vr/QPJko7sIkEo7CJBKOwiQSjsIkEo7CJBKOwiQSjsIkGon11KkztddMF+9tf+5pxkbXC6P1zzqd/rcetvfH2pW2/f5197cdy/vJysDZ063113pL8/WTPnmg8d2UWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUD+7lCavH735tFPc+o6/8v98j2h+J1kbfGuyu+62a6a79U9t9fvRh1vcMkZOnJ2sNQ3kTIPtv3T6dfOeQPJBkntJbhqz7E6S3SQ3Zl+XV7h9EamTibyNXwng0nGWf9fMlmRfa6rbLBGpttywm9lTAPbXoS0iUkNFTtDdRPKF7G1+8gMOyeUku0h2DSI9PpaI1FalYb8PwAIASwDsAnB36olmtsLMOs2sswVtFW5ORIqqKOxmtsfMhs1sBMD9APxbgESkdBWFneSsMT9eBcAfV1dESpfbz07yIQAXADiG5E4A3wJwAcklGO3y2w7gazVsY1XU+t7p31S5c6DTPx40HdHu1od7nPvCl37aXXfkLv+8cN+2WW79uDlvp2s3/Mpdt+hcAHnj0h9YNCVZm75um7uufyd+Wm7YzezacRY/UOH2RKQkulxWJAiFXSQIhV0kCIVdJAiFXSSIMLe4Fu5aIwtsvHGndM7bL3ldc27XGoDmhScla1tv9fdp09P+kMrHnvmWW5922atuvaZGcsrN6X+7HfD3aaV0ZBcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJIkw/e2EN3Ffuyrs+IOffVfT6hK1/nb6Vc3j3ke66Laf5/c3Tf++VitpUDxzx92v/MenfizclcxE6sosEobCLBKGwiwShsIsEobCLBKGwiwShsIsEEaefvWB/c3PHzGRtZF66BgCH5vnTAx/5yHq3XkiNrw/Y+vefc+scTk/5NW/xbnfdtou3V9KkCWFLa6H1bfCwX5/k/731H13/6zZ0ZBcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJIk4/e8H+5r4zj0/Weub7u7GtJ6cPf9o0t543NnsteeO+A8CZnf495dNb+5K17UvfrahNVWH+wO42XOnEyJmcceMH5/r99LWQe2QnOY/k4yS3kNxM8uZs+QySa0m+kn2fXvvmikilJvI2fgjAbWa2GMDnANxIcjGA2wGsM7OFANZlP4tIg8oNu5ntMrNns8cHAbwEYA6AKwCsyp62CsCVtWqkiBT3sT6zkzwBwBkA1gPoMLNdWWk3gI7EOssBLAeAdvhjjolI7Uz4bDzJKQB+AuAWM/vAGSMzMwDjnoUysxVm1mlmnS1oK9RYEanchMJOsgWjQf+hmf00W7yH5KysPgvA3to0UUSqIfdtPEkCeADAS2b2nTGl1QCWAbgr+/7ohLbo3Wpay9sxC97i2rbmmWTt2EraM0bBTp7aWuEPa3xdxy/c+ve+enWyRmysqEnVkDtEdpEpupE/lPRnF+xI1g4W2nLaRD6zfx7AVwC8SPK9384dGA35j0leD2AHgPRvVURKlxt2M3saQOq/uYuq2xwRqRVdLisShMIuEoTCLhKEwi4ShMIuEkT9b3Eta+rjott1+l3bnhj3SuH3feFo/zbQH913iVufee/P3XoRr97tDwX90qJ73fqi//iaX/9Z18du0ydB3lDSi6akr0HbUKNjsI7sIkEo7CJBKOwiQSjsIkEo7CJBKOwiQSjsIkHUtZ995KjJ6PvS2cl684A//m7rgcFkbdLenOGWe3rdsvX5wxqP9KbX7xlod9e9btrzbv3ADf5wXc/92wlufWjH68nawT/y+9H/9Q/vcet/ssO/BuDUmza59ZwRlRtXwesyrMnvZ39nyPud+2MIVEpHdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEg6trPPtwG9JzQnKz3zs8Zq/uY9Fjfk6f6s80MDk526/1v+33lGEm3jW/4I7+fv+9Gtz5ps9+2tt93yzhwdnrk+gsX+f3gt736Zbfe+udT3PpI/xa33nRkuj95pC89nfNvuuZD6WtCAOCxJ5ckawvwy2o3B4CO7CJhKOwiQSjsIkEo7CJBKOwiQSjsIkEo7CJB0HLu2yU5D8APAHQAMAArzOwekncCuAHAm9lT7zCzNd5rTeMMO5vlTPw6ac5st374JH/s9/5jW5O1g3PT1w4AgOVcPnBonn/X97RFb7v1mVPS99pvWz/fXffklW+69eGXt7p1GV/zaae49b/995XJ2q0nnFPxdtfbOvTY/nH/4iZyUc0QgNvM7FmSUwFsILk2q33XzP6u4paJSN1MZH72XQB2ZY8PknwJwJxaN0xEqutjfWYneQKAMwCszxbdRPIFkg+SnJ5YZznJLpJdgxgo1FgRqdyEw05yCoCfALjFzHoA3AdgAYAlGD3y3z3eema2wsw6zayzBf716yJSOxMKO8kWjAb9h2b2UwAwsz1mNmxmIwDuB7C0ds0UkaJyw06SAB4A8JKZfWfM8lljnnYVAP/2KhEp1UTOxn8ewFcAvEhyY7bsDgDXklyC0e647QD8uXtLNtT9hltvyql7A//6A0HXntd5eiK63XX9m3OlUsObX3brf7D6lmRt4funxKprImfjnwYwXr+d26cuIo1FV9CJBKGwiwShsIsEobCLBKGwiwShsIsEUdehpEVk1MI/q01fukdHdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgcoeSrurGyDcB7Biz6BgAb9WtAR9Po7atUdsFqG2VqmbbjjezcefwrmvYP7JxssvMOktrgKNR29ao7QLUtkrVq216Gy8ShMIuEkTZYV9R8vY9jdq2Rm0XoLZVqi5tK/Uzu4jUT9lHdhGpE4VdJIhSwk7yUpIvk9xK8vYy2pBCcjvJF0luJNlVclseJLmX5KYxy2aQXEvylez7uHPsldS2O0l2Z/tuI8nLS2rbPJKPk9xCcjPJm7Plpe47p1112W91/8xOshnArwH8LoCdAJ4BcK2ZbalrQxJIbgfQaWalX4BB8osAegH8wMxOz5Z9G8B+M7sr+49yupl9o0HadieA3rKn8c5mK5o1dppxAFcC+CpK3HdOu65GHfZbGUf2pQC2mtk2MzsM4GEAV5TQjoZnZk8B2P+hxVcAWJU9XoXRP5a6S7StIZjZLjN7Nnt8EMB704yXuu+cdtVFGWGfA+D1MT/vRGPN924AHiO5geTyshszjg4z25U93g2go8zGjCN3Gu96+tA04w2z7yqZ/rwonaD7qPPM7LMALgNwY/Z2tSHZ6GewRuo7ndA03vUyzjTj7ytz31U6/XlRZYS9G8C8MT/PzZY1BDPrzr7vBfAIGm8q6j3vzaCbfd9bcnve10jTeI83zTgaYN+VOf15GWF/BsBCkieSbAVwDYDVJbTjI0hOzk6cgORkABej8aaiXg1gWfZ4GYBHS2zLBzTKNN6pacZR8r4rffpzM6v7F4DLMXpG/lUAf1lGGxLtOgnA89nX5rLbBuAhjL6tG8TouY3rARwNYB2AVwD8N4AZDdS2fwLwIoAXMBqsWSW17TyMvkV/AcDG7Ovysved06667DddLisShE7QiQShsIsEobCLBKGwiwShsIsEobCLBKGwiwTxfx5QSatu7bxIAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["# B. Build the Model"],"metadata":{"id":"VyUA_nJ_rjkF"}},{"cell_type":"code","source":["# Definisikan model\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),        # hidden layer\n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])     # output layer"],"metadata":{"id":"CPnzaXgTqwZ1","executionInfo":{"status":"ok","timestamp":1646965059532,"user_tz":-420,"elapsed":3393,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Definisi:\n","1. **Sequential**: Mendefinisikan urutan lapisan dalam jaringan NN\n","2. **Flatten**: Mengubah gambar menjadi satu 1 dimensi. Ingat bahwa gambar kita berbentuk persegi 28x28. 784x1\n","3. **Dense**: Menambahkan lapisan neuron\n","\n","Setiap lapisan neuron membutuhkan fungsi aktivasi untuk memberi tahu neuron mana yang aktif atau tidak (neuron mana yang mengandung informasi).\n","1. **Relu**: Jika x>0 mengembalikan x, jika tidak mengembalikan 0\n","2. **Softmax**: Mengambil satu set nilai, lalu memilih nilai yang terbesar. Misalnya pada output layer, NN mengembalikan nilai `[0.1, 0.2, 3.5, 0.1, 8.5, 7.5, 0.1]` maka softmax mengubahnya menjadi `[0, 0, 0, 0, 1, 0 ,0]`\n"],"metadata":{"id":"A4xWJwLusKQK"}},{"cell_type":"markdown","source":["# C.Compile the Model\n","\n","Hal berikutnya, kita akan membungkus (membangun) model yang telah kita defenisikan sebelumnya.\n","\n","Kita proses compile, kita menambahkan **optimizer** dan **loss function**. "],"metadata":{"id":"r-DN0RZ210zj"}},{"cell_type":"code","source":["# Compile model\n","\n","model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics = ['accuracy'])"],"metadata":{"id":"DKfo3dHwsJ06","executionInfo":{"status":"ok","timestamp":1646966312438,"user_tz":-420,"elapsed":367,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["tf.random.set_seed(50)"],"metadata":{"id":"EmcByvtSzv-A","executionInfo":{"status":"ok","timestamp":1646965757094,"user_tz":-420,"elapsed":490,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["#D. Train the Model\n","\n","Latih jaringan NN dengan memanggil `model.fit`.\n","\n","Kita meminta jaringan NN mencari tahu hubungan antara data latih dan label latih yang sebenarnya. Jadi, di masa datang, jika kita memiliki data yang tidak terlihat (data baru) , maka jaringan NN dapat membuat prediksi labelnya."],"metadata":{"id":"TRo5QR1PxIlU"}},{"cell_type":"code","source":["%%time\n","\n","# Latih model\n","model.fit(training_images, training_labels, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pLRH9xMyxmNP","executionInfo":{"status":"ok","timestamp":1646965829158,"user_tz":-420,"elapsed":22314,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"98c9a3d9-3751-4e3f-c4b4-d555250a9107"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1948 - accuracy: 0.9261\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1918 - accuracy: 0.9282\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1851 - accuracy: 0.9301\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1821 - accuracy: 0.9322\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1766 - accuracy: 0.9335\n","CPU times: user 27.8 s, sys: 5.85 s, total: 33.7 s\n","Wall time: 21.9 s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fee180c6c90>"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["# E. Evaluate the Model"],"metadata":{"id":"-RxrBcug2D1h"}},{"cell_type":"code","source":["# Evaluasi model\n","\n","model.evaluate(test_images, test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjnxFox51N01","executionInfo":{"status":"ok","timestamp":1646966179266,"user_tz":-420,"elapsed":1313,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"d6ad1955-9356-4c6a-efbe-a3b5202bc685"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 2ms/step - loss: 0.3493 - accuracy: 0.8905\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.3492791950702667, 0.890500009059906]"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["# F. Eksplorasi"],"metadata":{"id":"lEcRyWv01vhu"}},{"cell_type":"markdown","source":["## Latihan 1\n","\n","Membuat prediski model kita dapat memanggil `model.predict`"],"metadata":{"id":"yCjp5SoU2NTr"}},{"cell_type":"code","source":["classifications = model.predict(test_images)\n","\n","print(classifications[9])  # melihat hasil prediksi dari indeks ke-n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EPGukRMY1vFu","executionInfo":{"status":"ok","timestamp":1646966799531,"user_tz":-420,"elapsed":574,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"335dd2f4-e414-436b-c257-a62a9084a3a7"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["[6.83365378e-11 2.78170939e-14 1.29736786e-11 8.60902468e-14\n"," 1.32014178e-13 1.53227472e-06 2.52606909e-14 9.99997616e-01\n"," 4.70503747e-10 8.27654787e-07]\n"]}]},{"cell_type":"markdown","source":["Menurut Anda, apa arti angka pada list tersebut?\n","\n","**Pertanyaan:** Apa angka pada list tersebut?\n","1. Nilai acak\n","2. Hasil klasifikasi 10 teratas dari model\n","3. Probabilitas item dari masing-masing kelas\n","\n","**Jawaban:** (3)\n","\n","Output dari model yang merupakan probabilitas nilai yang diklasifikasikan oleh model."],"metadata":{"id":"9RXZ_DaS2cF8"}},{"cell_type":"code","source":["print(test_labels[9])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJctS6uv2bkU","executionInfo":{"status":"ok","timestamp":1646966801755,"user_tz":-420,"elapsed":4,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"39897b0c-c8d6-4d7e-8b5e-d8d580eced7f"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n"]}]},{"cell_type":"markdown","source":["## Latihan 2\n","\n","Kita akan mencoba nilai yang berbeda untuk `dense layer`. Apakah hasilnya berbeda untuk loss, waktu pelatihan, dan akurasi?"],"metadata":{"id":"YLFY8rtd4Jeq"}},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","# Ganti jumlah neuron pada lapisan kedua\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),    \n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics = ['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"micpycTc3EsV","executionInfo":{"status":"ok","timestamp":1646967032008,"user_tz":-420,"elapsed":988,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"740621f0-a29d-4f4c-9cbc-cc2874c2d0f0"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}]},{"cell_type":"code","source":["%%time\n","model.fit(training_images, training_labels, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ne-9y7t04pH0","executionInfo":{"status":"ok","timestamp":1646967060494,"user_tz":-420,"elapsed":22344,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"ec5ac0f2-8706-46c4-cf26-616675109620"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.4677 - accuracy: 0.8315\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3577 - accuracy: 0.8703\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3216 - accuracy: 0.8809\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2955 - accuracy: 0.8895\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2766 - accuracy: 0.8972\n","CPU times: user 28.4 s, sys: 5.78 s, total: 34.2 s\n","Wall time: 22.3 s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fee17c58110>"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["Artinya, ketika menambahkan lebih banyak neuron, model harus melakukan lebih banyak kalkulasi. \n","\n","Hasilnya blm tentu lebih baik. Tetapi waktu komputasi yang dibutuhkan akan meningkat."],"metadata":{"id":"ortf847Z6le3"}},{"cell_type":"markdown","source":["## Latihan 3\n","\n","Kita akan mencoba menghapus layer `flatten()`"],"metadata":{"id":"gkQscqyc60Te"}},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","# model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","#                                     tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n","#                                     tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n","                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics = ['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"whNHG0HV4psm","executionInfo":{"status":"ok","timestamp":1646967671299,"user_tz":-420,"elapsed":1003,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"69b84161-dce1-49b7-9af2-5a6c34a1886d"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}]},{"cell_type":"code","source":["%%time\n","model.fit(training_images, training_labels, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":867},"id":"EUPheesC7GdL","executionInfo":{"status":"error","timestamp":1646967687032,"user_tz":-420,"elapsed":601,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"4315269d-1452-4290-aeb1-d86009697733"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-69a4e6fe7d14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.fit(training_images, training_labels, epochs=5)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1863, in sparse_categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5203, in sparse_categorical_crossentropy\n        labels=target, logits=output)\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)\n"]}]},{"cell_type":"markdown","source":["Akan terjadi error ketika pelatihan. Karena kita perlu mengubah data gambar kita (28 x 28) menjadi bentuk 1 dimensi (784 x 1)"],"metadata":{"id":"cNAMO-W67dMT"}},{"cell_type":"markdown","source":["## Latihan 4\n","\n","Kita akan mencoba mengubah nilai pada output layer. Misalnya kita ganti menjadi 5 neuron."],"metadata":{"id":"S_OKuFV77o4o"}},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","# model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","#                                     tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n","#                                     tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),    \n","                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics = ['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EgBcV38971S-","executionInfo":{"status":"ok","timestamp":1646967899481,"user_tz":-420,"elapsed":1046,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"0a34fd43-e28d-420c-82e4-9ae0f36d3b3e"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}]},{"cell_type":"code","source":["%%time\n","model.fit(training_images, training_labels, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7TSPXIPf771i","executionInfo":{"status":"ok","timestamp":1646967932388,"user_tz":-420,"elapsed":22266,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"fa5f4329-3a61-46bc-abd0-1de15a8257eb"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: nan - accuracy: 0.1000\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.1000\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.1000\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.1000\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.1000\n","CPU times: user 28.4 s, sys: 5.73 s, total: 34.1 s\n","Wall time: 22.2 s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fed9a0dfb90>"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["Kode bisa dijalankan, tetapi tidak mengembalikan nilai loss dan akurasi yang sesuai. Kenapa ?\n","\n","Neuron pada output layer harus sesuai dengan jumlah kelas yang akan kita klasifikasikan. Dalam kasus ini, kita memiliki 10 kelas. Maka, jumlah neuron pada output layer harus berjumlah 10."],"metadata":{"id":"kqvaDdTR8JO4"}},{"cell_type":"markdown","source":["## Latihan 5\n","\n","Kita akan mencoba menambahkan jumlah lapisan `dense layer` pada jaringan. "],"metadata":{"id":"ZDzuaQnK8f7i"}},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                   tf.keras.layers.Dense(128, activation=tf.nn.relu),\n","                                   tf.keras.layers.Dense(64, activation=tf.nn.relu),    \n","                                   tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics = ['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OWfvYAtq8IkH","executionInfo":{"status":"ok","timestamp":1646968106839,"user_tz":-420,"elapsed":768,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"72820022-0789-46de-aed8-49f1ea534dc8"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}]},{"cell_type":"code","source":["%%time\n","model.fit(training_images, training_labels, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tO3VWOeb8vwO","executionInfo":{"status":"ok","timestamp":1646968141768,"user_tz":-420,"elapsed":23373,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"c1f80a6c-2920-4cef-bdc8-90ad49ae9a9e"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.5002 - accuracy: 0.8216\n","Epoch 2/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.3695 - accuracy: 0.8654\n","Epoch 3/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.3320 - accuracy: 0.8784\n","Epoch 4/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.3083 - accuracy: 0.8858\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2882 - accuracy: 0.8922\n","CPU times: user 29.4 s, sys: 5.86 s, total: 35.2 s\n","Wall time: 23.3 s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fed827b99d0>"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["Bisa dikatakan, tidak ada pengaruh yang signifikan terhadap akurasi. Kenapa? karena data kita dalam kasus ini relatif sederhana. \n","\n","Untuk data yang jauh lebih kompleks, lapisan tambahan mungkin diperlukan.\n","\n","Ini juga berpengaruh dengan waktu komputasi, semakin banyak lapisan maka semakin banyak kalkulasi yang dilakukan oleh model."],"metadata":{"id":"ylCeBYlH87Sq"}},{"cell_type":"markdown","source":["## Latihan 6\n","\n","Kita akan mencoba dampak epoch terhadap proses pelatihan model."],"metadata":{"id":"paSkUSsy-EwG"}},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                   tf.keras.layers.Dense(128, activation=tf.nn.relu), \n","                                   tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics = ['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0SfgpKb3-M9b","executionInfo":{"status":"ok","timestamp":1646968690146,"user_tz":-420,"elapsed":845,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"b421cc7f-b861-4663-aa2d-a4ab34e3373d"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}]},{"cell_type":"code","source":["%%time\n","model.fit(training_images, training_labels, epochs=15)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXB7-XbS-Scl","executionInfo":{"status":"ok","timestamp":1646968586695,"user_tz":-420,"elapsed":65630,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"f9586e83-1d06-4802-91cb-87856eca9cc4"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.5007 - accuracy: 0.8240\n","Epoch 2/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3747 - accuracy: 0.8658\n","Epoch 3/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3379 - accuracy: 0.8779\n","Epoch 4/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3121 - accuracy: 0.8849\n","Epoch 5/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2947 - accuracy: 0.8903\n","Epoch 6/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2796 - accuracy: 0.8961\n","Epoch 7/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2677 - accuracy: 0.9007\n","Epoch 8/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2564 - accuracy: 0.9046\n","Epoch 9/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2459 - accuracy: 0.9081\n","Epoch 10/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2380 - accuracy: 0.9117\n","Epoch 11/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2298 - accuracy: 0.9141\n","Epoch 12/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2221 - accuracy: 0.9169\n","Epoch 13/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2167 - accuracy: 0.9192\n","Epoch 14/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2097 - accuracy: 0.9209\n","Epoch 15/15\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2034 - accuracy: 0.9233\n","CPU times: user 1min 23s, sys: 17.4 s, total: 1min 40s\n","Wall time: 1min 5s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fed826fb110>"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["%%time\n","model.fit(training_images, training_labels, epochs=30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PokuhWoF-T3p","executionInfo":{"status":"ok","timestamp":1646968822371,"user_tz":-420,"elapsed":129939,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"bb29f01f-ec9b-4038-9fd4-623c90531f18"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.4984 - accuracy: 0.8258\n","Epoch 2/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3763 - accuracy: 0.8648\n","Epoch 3/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3377 - accuracy: 0.8781\n","Epoch 4/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3123 - accuracy: 0.8853\n","Epoch 5/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2944 - accuracy: 0.8909\n","Epoch 6/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2795 - accuracy: 0.8969\n","Epoch 7/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2666 - accuracy: 0.9016\n","Epoch 8/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2573 - accuracy: 0.9040\n","Epoch 9/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2462 - accuracy: 0.9080\n","Epoch 10/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2378 - accuracy: 0.9121\n","Epoch 11/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2283 - accuracy: 0.9150\n","Epoch 12/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2219 - accuracy: 0.9169\n","Epoch 13/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2155 - accuracy: 0.9202\n","Epoch 14/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2090 - accuracy: 0.9219\n","Epoch 15/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2028 - accuracy: 0.9233\n","Epoch 16/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1970 - accuracy: 0.9258\n","Epoch 17/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1920 - accuracy: 0.9277\n","Epoch 18/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1867 - accuracy: 0.9302\n","Epoch 19/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1842 - accuracy: 0.9306\n","Epoch 20/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1761 - accuracy: 0.9338\n","Epoch 21/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1723 - accuracy: 0.9356\n","Epoch 22/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1680 - accuracy: 0.9376\n","Epoch 23/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1638 - accuracy: 0.9378\n","Epoch 24/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1590 - accuracy: 0.9398\n","Epoch 25/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1565 - accuracy: 0.9415\n","Epoch 26/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1527 - accuracy: 0.9426\n","Epoch 27/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1482 - accuracy: 0.9439\n","Epoch 28/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1457 - accuracy: 0.9461\n","Epoch 29/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1442 - accuracy: 0.9447\n","Epoch 30/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1400 - accuracy: 0.9479\n","CPU times: user 2min 45s, sys: 35.3 s, total: 3min 20s\n","Wall time: 2min 9s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fed825e3f10>"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["Ketika kita coba menggunakan 30 epoch, kita melihat loss dan akurasi naik turun. Ini lah yang bisa kita sebut sebagai 'overfitting'. Jika perlu bijak ketika menentukan epoch."],"metadata":{"id":"T8bcDDue_0eU"}},{"cell_type":"markdown","source":["## Latihan 7\n","\n","Saat kita melatih dengan banyak epoch, kita tidak ingin model kita stuck. \n","\n","Daripada kita menunggu selesai pelatihan dengan jumlah epoch yang banyak. Kita ingin model kita berhenti belajar ketika akurasi / loss mencapai nilai yang ditentukan.\n","\n","Kita akan terapkan callback."],"metadata":{"id":"LItCPsnsAIS6"}},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('accuracy')>0.9):\n","      print('\\nSudah sampai akurasi 90%, stop training!')\n","      self.model.stop_training = True\n","\n","callback = myCallback()\n","\n","mnist = tf.keras.datasets.fashion_mnist\n","\n","(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n","\n","training_images = training_images/255.0\n","test_images = test_images/255.0\n","\n","model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n","                                   tf.keras.layers.Dense(128, activation=tf.nn.relu), \n","                                   tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n","\n","model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics = ['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ew2wAPQEA45S","executionInfo":{"status":"ok","timestamp":1646969404469,"user_tz":-420,"elapsed":992,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"f5e6db98-330e-443e-ceea-3949f77b77cb"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}]},{"cell_type":"code","source":["%%time\n","model.fit(training_images, training_labels, epochs=30, callbacks=[callback])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQ1Lrmk-BcP0","executionInfo":{"status":"ok","timestamp":1646969436685,"user_tz":-420,"elapsed":30739,"user":{"displayName":"Kuncahyo Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj09o3Oga540RO6cBZ5AU63IC5LSoqsBNlZb_Jz=s64","userId":"17903335045350097388"}},"outputId":"7fdf44db-4ffb-4ffb-bb02-8336e1d557ce"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.4971 - accuracy: 0.8251\n","Epoch 2/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3745 - accuracy: 0.8654\n","Epoch 3/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3370 - accuracy: 0.8774\n","Epoch 4/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3111 - accuracy: 0.8847\n","Epoch 5/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2931 - accuracy: 0.8919\n","Epoch 6/30\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2797 - accuracy: 0.8975\n","Epoch 7/30\n","1857/1875 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.9012\n","Sudah sampai akurasi 90%, stop training!\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2676 - accuracy: 0.9012\n","CPU times: user 38.8 s, sys: 8.2 s, total: 47 s\n","Wall time: 30.7 s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fed824c7ed0>"]},"metadata":{},"execution_count":40}]}]}